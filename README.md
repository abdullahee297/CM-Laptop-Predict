ğŸ“ Laptop Eligibility Prediction Using Machine Learning

This project uses Logistic Regression to predict whether a university student is eligible to receive a laptop based on their Department, HSC (HEC) Percentage, and CGPA.

The dataset may contain missing student data, so those entries are removed to ensure accurate predictions.

ğŸ“Œ Project Objective

Predict laptop eligibility (Yes / No) for students
Handle missing student data
Encode categorical features properly
Train and evaluate a Logistic Regression model
Visualize model performanceRR
Allow real-time user input for prediction

ğŸ§  Technologies & Libraries Used

Python
Pandas â€“ Data handling
Scikit-learn â€“ Machine learning
Matplotlib â€“ Visualization

ğŸ“‚ Dataset Description (laptop.csv)

The dataset contains the following columns:

Column Name	Description
Department	Studentâ€™s department (CS, IT, EE, etc.)
HSC Percentage	Higher Secondary Certificate percentage
CGPA	Cumulative Grade Point Average
Status	Laptop eligibility (Yes / No)
ğŸ›  Step-by-Step Explanation
1ï¸âƒ£ Import Required Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt


ğŸ”¹ These libraries help in:

Reading data
Encoding categorical values
Training the ML model
Evaluating accuracy
Visualizing results

2ï¸âƒ£ Load the Dataset
lap = pd.read_csv("laptop.csv")

ğŸ”¹ Reads the dataset from a CSV file into a Pandas DataFrame.

3ï¸âƒ£ Data Cleaning & Preprocessing
lap["Status"] = lap["Status"].str.strip()
lap = lap.dropna()


âœ” Removes:

Extra spaces in the Status column
Any student record with missing data

ğŸ“Œ This ensures only complete student data is used for training.

4ï¸âƒ£ Encode Categorical Data
lap["Department"] = dep_encoder.fit_transform(lap["Department"])
y = status.fit_transform(lap["Status"])

ğŸ”¹ Machine learning models cannot understand text, so:

Departments are converted into numbers
Status (Yes / No) is converted into 0 / 1

5ï¸âƒ£ Feature Selection
x = lap[["Department", "HSC Percentage", "CGPA"]]


ğŸ”¹ These features are used to predict laptop eligibility.

6ï¸âƒ£ Train-Test Split
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=0
)


âœ” 80% data â†’ Training
âœ” 20% data â†’ Testing

This helps test how well the model performs on unseen data.

7ï¸âƒ£ Train the Logistic Regression Model
model = LogisticRegression()
model.fit(x_train, y_train)


ğŸ”¹ Logistic Regression is ideal for binary classification problems like:

Eligible / Not Eligible

8ï¸âƒ£ Model Prediction & Evaluation
ğŸ”¹ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)


Shows:

True Positives
True Negatives
False Positives
False Negatives

ğŸ”¹ Accuracy Score
acc = accuracy_score(y_test, y_pred)

ğŸ“Š Displays how accurately the model predicts eligibility.

9ï¸âƒ£ Data Visualization
ğŸ”¹ Accuracy Bar Chart

Shows overall model performance.

ğŸ”¹ Scatter Plot
plt.scatter(lap["HSC Percentage"], lap["CGPA"], c=y)


ğŸ“ˆ Visualizes how CGPA and HSC Percentage affect laptop eligibility.

ğŸ”Ÿ User Input Prediction
dep = input("Enter the Department: ")
hec = float(input("Enter your HEC Percentage: "))
cgpa = float(input("Enter your CGPA: "))


ğŸ”¹ Takes real-time student data from the user.

result = status.inverse_transform(pred_data)[0]
print("Result for selection:", result)


âœ” Outputs whether the student is Eligible or Not Eligible for the laptop.

ğŸ“Š Output Example
Enter the Department: CS
Enter your HEC Percentage: 85
Enter your CGPA: 3.5

Result for selection: Yes

ğŸš€ Future Improvements

Add real university dataset
Improve accuracy with feature scaling
Try advanced models (SVM, Random Forest)
Create a web or GUI interface

ğŸ“Œ Conclusion

This project demonstrates how Machine Learning can be used to:
Automate decision-making
Handle missing data
Predict student eligibility fairly
Itâ€™s ideal for students learning ML, logistic regression, and real-world data preprocessing.
